{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the CSV file\n",
    "hamburger = pd.read_csv(\"hamburger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BurgerKing</td>\n",
       "      <td>its the old tendercrisp that was used before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BurgerKing</td>\n",
       "      <td>Yea, they can get pretty huffy about that stuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BurgerKing</td>\n",
       "      <td>Yes BK delivers , please give all praise and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BurgerKing</td>\n",
       "      <td>I did too and it didn't work at all. I told th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McDonalds</td>\n",
       "      <td>I have actually been to this McDonald’s.  We w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                               body\n",
       "0  BurgerKing  its the old tendercrisp that was used before t...\n",
       "1  BurgerKing  Yea, they can get pretty huffy about that stuf...\n",
       "2  BurgerKing  Yes BK delivers , please give all praise and g...\n",
       "3  BurgerKing  I did too and it didn't work at all. I told th...\n",
       "4   McDonalds  I have actually been to this McDonald’s.  We w..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first 5 records.\n",
    "hamburger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  6000 non-null   object\n",
      " 1   body       6000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# viewing info method.\n",
    "hamburger.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the \"removed\" from the body column\n",
    "hamburger = hamburger.drop(hamburger.loc[hamburger[\"body\"]==\"[removed]\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the \"deleted\" from the body column\n",
    "hamburger = hamburger.drop(hamburger.loc[hamburger[\"body\"]==\"[deleted]\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5352 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  5352 non-null   object\n",
      " 1   body       5352 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 125.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# viewing info method.\n",
    "hamburger.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BurgerKing</th>\n",
       "      <td>3476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McDonalds</th>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            body\n",
       "subreddit       \n",
       "BurgerKing  3476\n",
       "McDonalds   1876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using groupby and count functions to view total entries\n",
    "hamburger.groupby([\"subreddit\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 0 for BurgerKing, and 1 for McDonalds\n",
    "hamburger[\"subreddit\"]=hamburger[\"subreddit\"].map({\"BurgerKing\":0, \"McDonalds\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating X for independent variable\n",
    "X = hamburger[\"body\"]\n",
    "\n",
    "# creating y for dependent variable\n",
    "y = hamburger[\"subreddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.649477\n",
       "1    0.350523\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using value_counts to see if it is Balanced\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datasets balance is 65-35%. This is not much unbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Multinomial Naive Bayes\n",
    "\n",
    "In the first model we are using term frequency–inverse document frequency​ vectorizer.\n",
    "Our estimator is going to be Multinomial Naive Baise, because our target values are binary.\n",
    "\n",
    "We are going pass, manually created `stop_words` and `none` stopwords in the vectorizer. Also, for `ngram_range` we are passing (1,1) and (1,3). \n",
    "\n",
    "For estimator Hyperparameters, we are going to use [0.01, 0.1, 1] as alpha parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Pipeline with transformer and estimator\n",
    "pipe = Pipeline([\n",
    "    (\"tfdif\",TfidfVectorizer()), #Tfidf will be our transformer\n",
    "    (\"mnb\", MultinomialNB())\n",
    "    # multinomial NB model will be used as estimator\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating manual stopwords.\n",
    "stop_words = [\"McDonalds\", \"McDonald's\", \"whopper\", \"Big Mac\", \"King\", \"loving\", \"BK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters dictionary\n",
    "pipe_params = {\n",
    "    'tfdif__stop_words': [stop_words, 'english'],\n",
    "    'tfdif__ngram_range':[(1,1),(1,2)],\n",
    "    \"mnb__alpha\":[0.01, 0.1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating Gridsearch with pipe, and given parameters. Shows limited parameters (verbose=1)\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, verbose=1, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   10.0s finished\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfdif', TfidfVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid={'mnb__alpha': [0.01, 0.1, 1],\n",
       "                         'tfdif__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'tfdif__stop_words': [['McDonalds', \"McDonald's\",\n",
       "                                                'whopper', 'Big Mac', 'King',\n",
       "                                                'loving', 'BK'],\n",
       "                                               'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model to our data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99721059972106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the best score of the pipeline\n",
    "gs_best_score = gs.best_score_\n",
    "gs_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988681380871534"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing dataset score\n",
    "gs_test_score = gs.score(X_test, y_test)\n",
    "gs_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfdif',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                 stop_words=['McDonalds', \"McDonald's\",\n",
       "                                             'whopper', 'Big Mac', 'King',\n",
       "                                             'loving', 'BK'])),\n",
       "                ('mnb', MultinomialNB(alpha=0.01))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the best extimator to a variable\n",
    "mnb = gs.best_estimator_\n",
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 0.01,\n",
       " 'tfdif__ngram_range': (1, 2),\n",
       " 'tfdif__stop_words': ['McDonalds',\n",
       "  \"McDonald's\",\n",
       "  'whopper',\n",
       "  'Big Mac',\n",
       "  'King',\n",
       "  'loving',\n",
       "  'BK']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the best parameters.\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating prediction and assigning them to an Numpy array\n",
    "mnb_predict = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Burger King</th>\n",
       "      <th>Predicted McDonald's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Burger King</th>\n",
       "      <td>1148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual McDonald's</th>\n",
       "      <td>2</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Burger King  Predicted McDonald's\n",
       "Actual Burger King                   1148                     0\n",
       "Actual McDonald's                       2                   617"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are creating a confusion matrix, and tn, fp, fn, tp variables\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, mnb_predict).ravel()\n",
    "\n",
    "# creating a dataframe to present the confusion matrix\n",
    "mnb_cm = pd.DataFrame(confusion_matrix(y_test, mnb_predict), \n",
    "                      index=[\"Actual Burger King\", \"Actual McDonald's\"], \n",
    "                      columns=[\"Predicted Burger King\", \"Predicted McDonald's\"])\n",
    "mnb_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sensitivity on Multinomial Naive Bayes.\n",
    "\n",
    "mnb_sens = tp/(tp+fn)\n",
    "\n",
    "print(f'Sensitivity: {round(mnb_sens, 2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate specificity on Multinomial Naive Bayes.\n",
    "\n",
    "mnb_spec = tn/(tn+fp)\n",
    "\n",
    "print(f'Specificity: {round(mnb_spec, 3)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of prediction probabilities for McDonald's\n",
    "mnb_pred_proba = [i[1] for i in mnb.predict_proba(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McDonald's probabilities and true values dataframe\n",
    "mnb_pred_df = pd.DataFrame({\"true_values\": y_test, \"preds_probs\": mnb_pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999921194688522"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the ROC score\n",
    "roc_auc_score(mnb_pred_df[\"true_values\"], mnb_pred_df[\"preds_probs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values. (Dashed red line in image.)\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(mnb_pred_df, 'true_values', 'preds_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(mnb_pred_df, 'true_values', 'preds_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title(f'ROC Curve with AUC = {round(roc_auc_score(mnb_pred_df[\"true_values\"], mnb_pred_df[\"preds_probs\"]),3)}', fontsize=22)\n",
    "plt.ylabel('Sensitivity', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Conclusion \n",
    "\n",
    "Our Multinomial Naive Bayes model is very close to a perfect model.\n",
    "The accuracy score on both test and train datasets is above 99%\n",
    "\n",
    "The best parameters are 0.01 for alpha value; and (1, 2) is the best 'ngram_range' value.\n",
    "\n",
    "Also, sensitivity and specificity are 99%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - K-Nearest Neighbors \n",
    "\n",
    "In the second model we are using term frequency–inverse document frequency​ vectorizer.\n",
    "Our choise of estimator is KNN. \n",
    "\n",
    "We are going pass, manually created `stop_words` and `none` stopwords in the vectorizer. Also, for `ngram_range` we are passing (1,1), (1,2) and (1,3). \n",
    "\n",
    "For estimator Hyperparameters, we are going to use [3, 5, 7] for number of neighbors. Also, we are going to try both Manhattan distance and Eucledian distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Pipeline\n",
    "pipe_2 = Pipeline([\n",
    "    (\"tfdif\",TfidfVectorizer()), #Tfidf will be our transformer\n",
    "    (\"knn\", KNeighborsClassifier()) # KNN model will be used as estimator\n",
    "               ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters dictionary\n",
    "pipe_2_params = { \n",
    "    'tfdif__stop_words': [stop_words, 'english'],\n",
    "    'tfdif__ngram_range':[(1,1),(1,2), (1,3)],\n",
    "    \"knn__n_neighbors\":[3,5,7],\n",
    "    \"knn__p\":[1,2],\n",
    "#     \"knn__weights\":[\"uniform\", \"distance\"]   #I was going to pass these hyperparameters but my computer couldn't handle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating Gridsearch with pipe, and given parameters. Shows limited parameters (verbose=1)\n",
    "gs_2 = GridSearchCV(pipe_2, param_grid=pipe_2_params, verbose=1, cv=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  1.0min finished\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfdif', TfidfVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2],\n",
       "                         'tfdif__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfdif__stop_words': [['McDonalds', \"McDonald's\",\n",
       "                                                'whopper', 'Big Mac', 'King',\n",
       "                                                'loving', 'BK'],\n",
       "                                               'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the train data\n",
    "gs_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905160390516038"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the best score of the pipeline\n",
    "gs_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 3,\n",
       " 'knn__p': 1,\n",
       " 'tfdif__ngram_range': (1, 1),\n",
       " 'tfdif__stop_words': ['McDonalds',\n",
       "  \"McDonald's\",\n",
       "  'whopper',\n",
       "  'Big Mac',\n",
       "  'King',\n",
       "  'loving',\n",
       "  'BK']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "gs_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the best estimator to a variable\n",
    "knn = gs_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988681380871534"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the score for testing data\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a numpy array for predictions\n",
    "knn_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Burger King</th>\n",
       "      <th>Predicted McDonald's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Burger King</th>\n",
       "      <td>1148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual McDonald's</th>\n",
       "      <td>2</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Burger King  Predicted McDonald's\n",
       "Actual Burger King                   1148                     0\n",
       "Actual McDonald's                       2                   617"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are creating a confusion matrix, and tn, fp, fn, tp variables\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, knn_predict).ravel()\n",
    "\n",
    "# creating a dataframe to present the confusion matrix\n",
    "knn_cm = pd.DataFrame(confusion_matrix(y_test, knn_predict), \n",
    "                      index=[\"Actual Burger King\", \"Actual McDonald's\"], \n",
    "                      columns=[\"Predicted Burger King\", \"Predicted McDonald's\"])\n",
    "knn_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sensitivity on KNN.\n",
    "\n",
    "knn_sens = tp/(tp+fn)\n",
    "\n",
    "print(f'Sensitivity: {round(knn_sens, 2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate specificity on KNN.\n",
    "\n",
    "knn_spec = tn/(tn+fp)\n",
    "\n",
    "print(f'Specificity: {round(knn_spec, 3)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of prediction probabilities for McDonald's\n",
    "knn_pred_proba = [i[1] for i in knn.predict_proba(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McDonald's probabilities and true values dataframe\n",
    "knn_pred_df = pd.DataFrame({\"true_values\": y_test, \"preds_probs\": knn_pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983844911147011"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the ROC score\n",
    "knn_roc_auc_score = roc_auc_score(knn_pred_df[\"true_values\"], knn_pred_df[\"preds_probs\"])\n",
    "knn_roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Results\n",
    "Our K-Nearest Neighbors model is also very close to a perfect model. The accuracy score on both test and train datasets is above 99%\n",
    "\n",
    "We used GridSearchCV to find the optimal parameters.\n",
    "The best parameters are 0.01 for alpha value; and (1, 2) is the best 'ngram_range' value.\n",
    "\n",
    "Also, sensitivity and specificity are above 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Logistic Regression\n",
    "In the third model we are using term frequency–inverse document frequency​ vectorizer. \n",
    "\n",
    "Our choise of estimator is going to be Logistic Regression.\n",
    "\n",
    "We are going pass, manually created stop_words and \"English\" stopwords in the vectorizer. Also, for ngram_range we are passing (1,1), (1,2) and (1,3).\n",
    "\n",
    "For estimator Hyperparameters, we are going to use both regularizations (Ridge and Lasso). Also, C value choices will be 5.5 and 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Pipeline.\n",
    "pipe_3 = Pipeline([\n",
    "    (\"tfdif\",TfidfVectorizer()), #Tfidf will be our transformer\n",
    "    (\"lr\", LogisticRegression()) # LR model will be used as estimator\n",
    "               ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters dictionary\n",
    "pipe_3_params ={\n",
    "    \"tfdif__stop_words\": [stop_words, 'english'],\n",
    "    'tfdif__ngram_range':[(1,1),(1,2), (1,3)],\n",
    "    \"lr__penalty\":[\"l1\",\"l2\"],\n",
    "    \"lr__solver\":[\"liblinear\"],\n",
    "    \"lr__C\":[5.5, 6]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating Gridsearch with pipe, and given parameters. Shows limited parameters (verbose=1)\n",
    "gs_3 = GridSearchCV(pipe_3, param_grid=pipe_3_params, verbose=1, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.3min finished\n",
      "/Users/kemalcanalaeddinoglu/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['big', 'bk', 'king', 'mac', 'mcdonald', 'mcdonalds'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfdif', TfidfVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'lr__C': [5.5, 6], 'lr__penalty': ['l1', 'l2'],\n",
       "                         'lr__solver': ['liblinear'],\n",
       "                         'tfdif__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfdif__stop_words': [['McDonalds', \"McDonald's\",\n",
       "                                                'whopper', 'Big Mac', 'King',\n",
       "                                                'loving', 'BK'],\n",
       "                                               'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the train data\n",
    "gs_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99721059972106"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the best score\n",
    "gs_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 5.5,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear',\n",
       " 'tfdif__ngram_range': (1, 1),\n",
       " 'tfdif__stop_words': ['McDonalds',\n",
       "  \"McDonald's\",\n",
       "  'whopper',\n",
       "  'Big Mac',\n",
       "  'King',\n",
       "  'loving',\n",
       "  'BK']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = gs_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99721059972106"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the accuracy on the training data \n",
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988681380871534"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the accuracy on the testing data \n",
    "\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a numpy array for predictions\n",
    "\n",
    "lr_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Burger King</th>\n",
       "      <th>Predicted McDonald's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Burger King</th>\n",
       "      <td>1148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual McDonald's</th>\n",
       "      <td>2</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Burger King  Predicted McDonald's\n",
       "Actual Burger King                   1148                     0\n",
       "Actual McDonald's                       2                   617"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are creating a confusion matrix, and tn, fp, fn, tp variables\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_predict).ravel()\n",
    "\n",
    "# creating a dataframe to present the confusion matrix\n",
    "lr_cm = pd.DataFrame(confusion_matrix(y_test, lr_predict), \n",
    "                      index=[\"Actual Burger King\", \"Actual McDonald's\"], \n",
    "                      columns=[\"Predicted Burger King\", \"Predicted McDonald's\"])\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sensitivity on Logistic Regression model.\n",
    "\n",
    "lr_sens = tp/(tp+fn)\n",
    "\n",
    "print(f'Sensitivity: {round(lr_sens, 2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate specificity on Logistic Regression model.\n",
    "\n",
    "lr_spec = tn/(tn+fp)\n",
    "\n",
    "print(f'Specificity: {round(lr_spec, 3)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of prediction probabilities for McDonald's\n",
    "lr_pred_proba = [i[1] for i in lr.predict_proba(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McDonald's probabilities and true values dataframe\n",
    "lr_pred_df = pd.DataFrame({\"true_values\": y_test, \"preds_probs\": lr_pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999915565737703"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the ROC score\n",
    "lr_roc_auc_score = roc_auc_score(lr_pred_df[\"true_values\"], lr_pred_df[\"preds_probs\"])\n",
    "lr_roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Results\n",
    "\n",
    "Our Logistic Regression model is also very close to a perfect model. The accuracy score on both test and train datasets is above 99%\n",
    "\n",
    "We used GridSearchCV to find the optimal parameters. The best parameters are 0.01 for alpha value; and (1, 2) is the best 'ngram_range' value for our transformer.\n",
    "\n",
    "Also, sensitivity and specificity are above 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "\n",
    "\n",
    "We created 3 models in order to make predictions.\n",
    "\n",
    "\n",
    "Our first model is Multinomial Naive Bayes. We used term frequency–inverse document frequency vectorizer to transform the data. Both the transformer and the estimator were instantiated in the Pipeline. With a group of hyperparameters, we used GridSearchCV. The hyperparamteres that we passed were manually created `stop_words` and `English` stopwords; (1,1), (1,2) for ngram_range for vectorizer. We passed these numbers for alpha value for Multinomial Naive Bayes; 0.01, 0.1, 1. Our GridSearch process fit 60 models to our data. In the first model the accuracy scores were close to 100%. The   GridSearch also gave us the best parameters. For this model the best hyperparameters are 'alpha': 0.01, 'ngram_range': (1, 2), and the `stop_words` that we created.\n",
    "\n",
    "\n",
    ">stop_words = [\"McDonalds\", \"McDonald's\", \"whopper\", \"Big Mac\", \"King\", \"loving\", \"BK\"]\n",
    "\n",
    "Our second model is K-Nearest Neighbors. We used same vectorizer to transform the data. Both the transformer and the estimator were put in the Pipeline. We passed a group of hyperparameters to GridSearchCV. The hyperparamteres that we passed were manually created `stop_words` and `English` stopwords; (1,1), (1,2) and (1,3) for ngram_range for vectorizer.  \n",
    "Also we included k=3, k=5, and k=7 for KNN model. Additionally, we searched for Manhattan and Eucledian distances. Our GridSearch process fit 108 models to our data. In this model the accuracy scores were close to 100%. The   GridSearch also gave us the best parameters. TT=he best hyperparameters are 'knn__n_neighbors': 3, 'knn__p': 1, 'tfdif__ngram_range': (1, 1), 'tfdif__stop_words': 'english'.\n",
    "\n",
    "\n",
    "Our third choice of estimator is Logistic Regression.\n",
    "We passed manually created `stop_words` and `English` stopwords in the vectorizer. Also, for ngram_range we are passing (1,1), (1,2) and (1,3).\n",
    "For estimator Hyperparameters, we included both regularizations (Ridge and Lasso). Also, C value choices will be 5.5 and 6. Our GridSearch process fit 120 models to our data. In this model the accuracy scores were also close to 100%. The GridSearch also gave us the best parameters. The best hyperparameters are 'C Value': 0.01, 'penalty': LASSO, 'ngram_range': (1, 1), and the `stop_words` that we created.\n",
    "\n",
    "\n",
    "|Estimator|Transformer|Best Score|Test Data Score| ROC_AUC Score|Sensitivity|Specificity |\n",
    "|---|-------------|------------|-------------|-----------------------|----------|-------------|\n",
    "|Multinomial Naive Bayes|TF-IDF| 99% | 99% | 99% | 100% | 99% |\n",
    "|K-Nearest Neighbors|TF-IDF| 98% | 99% | 99% | 99% | 100% |\n",
    "|Logistic Regression|TF-IDF| 99% | 99% | 100% | 99% | 99% |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
